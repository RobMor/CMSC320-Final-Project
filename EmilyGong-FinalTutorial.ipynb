{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Final Tutorial Notebook</center></h1>\n",
    "<h3><center>Emily Gong, Robert Morrison</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Flag_of_the_United_Nations_%281945-1947%29.svg/2000px-Flag_of_the_United_Nations_%281945-1947%29.svg.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "- ### Introduction\n",
    "    - Overview\n",
    "    - Tools\n",
    "- ### Data Collection\n",
    "    - Loading Data\n",
    "    - Cleaning Data **(@Robbie please make sure these categories match what you did or edit it to do so)**\n",
    "    - Scraping Data  \n",
    "\n",
    "- ### Exploratory Data Anlysis\n",
    "    - Explore Words\n",
    "    - Explore Entities\n",
    "    - Explore Topics\n",
    "    - Explore Votes \n",
    "- ### Analysis & ML\n",
    "    - t-SNS\n",
    "- ### Conclusions and Further Actions\n",
    "    - Challenges\n",
    "    - Conclusions\n",
    "    - Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "**Background:**  \n",
    "The United Nations is an international organization of independent states to promote peace and international cooperation and security. Currently, there are 193 sovereign states and they meet every year in regular session on the Tuesday of the third week in September. Every year, the UN created a theme to focus on. Interestingly, this year’s theme is “Making the United Nations relevant to all people: global leadership and shared responsibilities for peaceful, equitable and sustainable societies”. In this notebook we are taking up the challenge of making the UN relevant by exploring the transcripts from the general debates and the votes from each country. \n",
    "\n",
    "**Purpose:**  \n",
    "The original intention was to look at the transcripts from the debate and predict the country the speaker was from. However, after analyzing the dataset there were challenges that redirected us to find a different purpose. These challenges are mentioned later. After reevaluating, we have decided to ... {UPDATE TEXT HERE}\n",
    "\n",
    "\n",
    "**Datasets:**\n",
    "- The UN General Debates dataset includes the general debates at the UN from 1970 - 2016. Information such as the session ID, year, country (ISO 3166 Alpha-3 country code 1), and transcription is included. \n",
    "    - https://www.kaggle.com/unitednations/un-general-debates?fbclid=IwAR3Onf0CDZsw-dCwNlmj85hfvq12KavEpkyIkKN-FGguAuIyzpaqwvREhC0\n",
    "\n",
    "- The UN General Assembly Votes dataset includes three separate csvs, resolutions, states, and votes. This dataset ranges from 1946-2015 and contains the votes of each country during various years. Specifically, it contains votes relating to topics such as human rights, nuclear development, and a few other categories. \n",
    "    - https://www.kaggle.com/unitednations/general-assembly\n",
    "\n",
    "\n",
    "**Personal Investment:**  \n",
    "On a personal level, we are interested in looking at this data because there are a lot of tools relating to NLP and we are interested in utilizing these tools to better understand what has been developed to process language. (Note Emily is a Computer Science and Linguistics Major). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "**Processing**  \n",
    "- NLTK\n",
    "    - suite of libraries for working with human language\n",
    "    - use cases:\n",
    "        - tokenization: separate corpra by tokens (words)\n",
    "        - part of speech tagging: label the type of speech\n",
    "        - chunking: segments and labels multi-token sequences\n",
    "    - widely used for teaching and research\n",
    "- spaCy\n",
    "    - advance library to implement nlp\n",
    "    - use cases:\n",
    "        - entity detection\n",
    "            - model of English\n",
    "    - widely used for production usage\n",
    "\n",
    "**Visualization** \n",
    "- gensim\n",
    "    - visualizing topic models\n",
    "- pyLDAvis\n",
    "    - visualizing topic models\n",
    "- bokeh\n",
    "    - Visualizing LDA results \n",
    "\n",
    "**Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# regular expressions\n",
    "import re\n",
    "\n",
    "# scraping \n",
    "import requests\n",
    "import bs4\n",
    "\n",
    "# processing\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "from spacy import displacy #display word entities\n",
    "import en_core_web_sm #language model\n",
    "from collections import Counter\n",
    "nlp = en_core_web_sm.load() \n",
    "\n",
    "# Below are libraries for LDA using gensim which is provides less control \n",
    "from nltk.corpus import stopwords #stop words to be filited out\n",
    "from gensim import models, corpora  #Used for LDA topic modeling\n",
    "from sklearn.metrics.pairwise import euclidean_distances \n",
    "import pyLDAvis.gensim #python library for interactive topic model visualization\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "# evaluating the model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "#Below are libraries for LDA using sklearn\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>MDV</td>\n",
       "      <td>﻿It is indeed a pleasure for me and the member...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>FIN</td>\n",
       "      <td>﻿\\nMay I begin by congratulating you. Sir, on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>NER</td>\n",
       "      <td>﻿\\nMr. President, it is a particular pleasure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>URY</td>\n",
       "      <td>﻿\\nDuring the debate at the fortieth session o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>1989</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>﻿I should like at the outset to express my del...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session  year country                                               text\n",
       "0       44  1989     MDV  ﻿It is indeed a pleasure for me and the member...\n",
       "1       44  1989     FIN  ﻿\\nMay I begin by congratulating you. Sir, on ...\n",
       "2       44  1989     NER  ﻿\\nMr. President, it is a particular pleasure ...\n",
       "3       44  1989     URY  ﻿\\nDuring the debate at the fortieth session o...\n",
       "4       44  1989     ZWE  ﻿I should like at the outset to express my del..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debates = pd.read_csv(\"un-general-debates.csv\")\n",
    "debates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7507\n"
     ]
    }
   ],
   "source": [
    "print(len(debates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MDV' 'FIN' 'NER' 'URY' 'ZWE' 'PHL' 'SDN' 'RUS' 'CHN' 'ESP' 'SUR' 'ARG'\n",
      " 'SLV' 'MYS' 'NPL' 'PRT' 'COL' 'BLR' 'MAR' 'LCA' 'EGY' 'MEX' 'BEL' 'BRN'\n",
      " 'RWA' 'CAN' 'ALB' 'GRC' 'KNA' 'GUY' 'LBR' 'ATG' 'MOZ' 'JPN' 'YDYE' 'GAB'\n",
      " 'BGD' 'SWE' 'TUR' 'TCD' 'SYR' 'CMR' 'JAM' 'LUX' 'ITA' 'AGO' 'CRI' 'CSK'\n",
      " 'BFA' 'MNG' 'BHR' 'HTI' 'OMN' 'CIV' 'TGO' 'CYP' 'MUS' 'MMR' 'ARE' 'GTM'\n",
      " 'GRD' 'LBY' 'LKA' 'TZA' 'SGP' 'NOR' 'LAO' 'ISL' 'AFG' 'CHL' 'DMA' 'UKR'\n",
      " 'KEN' 'BLZ' 'FRA' 'MLI' 'VCT' 'VEN' 'MLT' 'GHA' 'GIN' 'GBR' 'ISR' 'YUG'\n",
      " 'BRB' 'IRQ' 'HUN' 'AUT' 'POL' 'GNB' 'BWA' 'MRT' 'SWZ' 'DNK' 'DOM' 'MDG'\n",
      " 'NIC' 'BDI' 'CUB' 'IRN' 'PAK' 'SEN' 'BGR' 'YEM' 'STP' 'NLD' 'VUT' 'BOL'\n",
      " 'PNG' 'SLB' 'DEU' 'ROU' 'KHM' 'TUN' 'BRA' 'IND' 'IDN' 'AUS' 'COD' 'HND'\n",
      " 'GNQ' 'FJI' 'IRL' 'DZA' 'USA' 'LSO' 'GMB' 'PER' 'DDR' 'THA' 'JOR' 'COG'\n",
      " 'NGA' 'ECU' 'SAU' 'QAT' 'SYC' 'ETH' 'TTO' 'PRY' 'VNM' 'NZL' 'PAN' 'MWI'\n",
      " 'DJI' 'BEN' 'SOM' 'ZMB' 'CPV' 'BHS' 'KWT' 'UGA' 'COM' 'ZAF' 'LBN' 'SLE'\n",
      " 'KOR' 'BIH' 'TON' 'EU' 'HRV' 'NRU' 'TUV' 'NAM' 'SMR' 'LIE' 'MKD' 'TLS'\n",
      " 'FSM' 'KIR' 'BTN' 'SVK' 'WSM' 'MNE' 'GEO' 'LTU' 'AND' 'TJK' 'MHL' 'EST'\n",
      " 'LVA' 'CAF' 'TKM' 'MDA' 'SSD' 'KGZ' 'AZE' 'PSE' 'PRK' 'CZE' 'ERI' 'ARM'\n",
      " 'UZB' 'PLW' 'VAT' 'MCO' 'CHE' 'KAZ' 'SVN']\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "countries = debates[\"country\"].unique()\n",
    "print(countries)\n",
    "print(len(countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1989 1970 2013 1985 2008 1991 1986 2002 1975 1996 2012 1997 1978 1988\n",
      " 2010 1984 1995 2009 1971 1976 1983 1979 1999 2005 1987 1982 1998 2003\n",
      " 2004 1980 2014 2011 1974 2015 1993 1977 1981 2000 1992 1990 1973 1994\n",
      " 1972 2006 2007 2001]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "years = debates[\"year\"].unique()\n",
    "print(years)\n",
    "print(len(years))\n",
    "# 46 Examples of each country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a decoding table and access to each countries Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3\"\n",
    "r = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = soup.find(\"div\", class_=\"plainlist\").find(\"ul\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {} # dict {country code : [Country Name, wikipedia link]}\n",
    "\n",
    "for child in found.children:\n",
    "    if isinstance(child, bs4.Tag):\n",
    "        c_code = child.find(\"span\").text\n",
    "        link = child.find(\"a\").get(\"href\")\n",
    "        country = child.find(\"a\").text\n",
    "        \n",
    "        lookup[c_code] = [country, link]\n",
    "\n",
    "lookup[\"CSK\"] = [\"Czechoslovakia\", \"/wiki/Czechoslovakia\"]\n",
    "lookup[\"YDYE\"] = [\"South Yemen\", \"/wiki/South_Yemen\"]\n",
    "lookup[\"YUG\"] = [\"Yugoslavia\", \"/wiki/Yugoslavia\"]\n",
    "lookup[\"DDR\"] = [\"East Germany\", \"/wiki/East_Germany\"]\n",
    "lookup[\"EU\"] = [\"European Union\", \"/wiki/European_Union\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "debates[\"name\"] = [lookup[code][0] for code in debates[\"country\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is indeed a pleasure for me and the members of my delegation to extend to Ambassador Garba our si\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the first transcript\n",
    "sample_text = debates.loc[0][\"text\"]\n",
    "sample_text = sample_text.replace(u'\\ufeff', '')\n",
    "print(sample_text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_debates(debates):\n",
    "    docs = []\n",
    "    stop_words = stopwords.words('english')\n",
    "    for transcript in debates['text']: \n",
    "        if transcript is not None:\n",
    "            transcript = transcript.replace(u'\\ufeff', '')\n",
    "            tokens = nltk.word_tokenize(transcript.lower())\n",
    "            docs.append([t.lower() for t in tokens if t not in stop_words and re.match('[a-zA-Z\\-][a-zA-Z\\-]{2,}', t)])\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['indeed', 'pleasure', 'members', 'delegation', 'extend', 'ambassador', 'garba', 'sincere', 'congratulations', 'election', 'presidency', 'forty-fourth', 'session', 'general', 'assembly', 'election', 'high', 'office', 'well-deserved', 'tribute', 'personal', 'qualities', 'experience', 'fully', 'confident', 'able', 'wise', 'leadership', 'assembly', 'consolidate', 'gains', 'achieved', 'past', 'year', 'delegation', 'associates', 'previous', 'speakers', 'expressing', 'appreciation', 'dedicated', 'efforts', 'predecessor', 'excellency', 'dante', 'caputo', 'exemplary', 'manner', 'discharged', 'duties', 'president', 'forty-third', 'session', 'general', 'assembly', 'previous', 'years', 'delegation', 'wishes', 'note', 'satisfaction', 'gratitude', 'assiduous', 'unrelenting', 'efforts', 'exerted', 'secretary-general', 'united', 'nations', 'cause', 'peace', 'international', 'harmony', 'pay', 'tribute', 'untiring', 'efforts', 'promote', 'conditions', 'conducive', 'realization', 'noble', 'principles', 'enshrined', 'charter', 'united', 'nations', 'praise', 'congratulate', 'successes', 'organization', 'achieved', 'recent', 'years', 'particularly', 'praise', 'renewed', 'faith', 'regeneration', 'confidence', 'organization', 'ability', 'play', 'instrumental', 'role', 'peaceful', 'settlement', 'disputes', 'today', 'find', 'important', 'crossroads', 'recent', 'years', 'witnessed', 'welcome', 'positive', 'change', 'international', 'political', 'climate', 'confrontational', 'tone', 'evident', 'super-power', 'relations', 'long', 'ago', 'continues', 'show', 'signs', 'thawing', 'time', 'number', 'regional', 'sub', 'regional', 'conflicts', 'taken', 'momentous', 'strides', 'towards', 'resolution', 'many', 'protracted', 'conflicts', 'show', 'signs', 'hope', 'movement', 'though', 'one', 'might', 'argue', 'present', 'situation', 'continues', 'delicate', 'process', 'made', 'hardly', 'escape', 'notice', 'indeed', 'worthy', 'recognition', 'developments', 'southern', 'africa', 'particularly', 'namibia', 'regard', 'implementation', 'united', 'nations', 'independence', 'plan', 'welcome', 'signals', 'hope', 'amidst', 'hopes', 'still', 'dark', 'reminders', 'precariousness', 'global', 'political', 'reconciliation', 'number', 'problems', 'remain', 'unsolved', 'several', 'conflicts', 'middle', 'east', 'continue', 'simmer', 'therefore', 'important', 'crossroads', 'feel', 'enough', 'good', 'set', 'motion', 'process', 'evolution', 'towards', 'peace', 'stability', 'see', 'signs', 'human', 'intellect', 'resourceful', 'enough', 'devise', 'ideas', 'conducive', 'survival', 'fresh', 'concepts', 'peace', 'security', 'gained', 'currency', 'time', 'continue', 'live', 'dark', 'shadow', 'nuclear', 'devices', 'proliferation', 'nuclear', 'weapons', 'horizontally', 'vertically', 'tragic', 'reminder', 'difficulties', 'obstacles', 'stand', 'mankind', 'lasting', 'peace', 'economic', 'front', 'hard', 'choices', 'need', 'made', 'witnessed', 'one', 'longest', 'spells', 'growth', 'industrialized', 'countries', 'situation', 'south', 'particularly', 'least', 'developed', 'countries', 'continues', 'deteriorate', 'benefits', 'trade', 'continue', 'disproportionate', 'commodity', 'prices', 'regained', 'value', 'real', 'terms', 'aid', 'flows', 'continue', 'inadequate', 'debt', 'burden', 'borne', 'many', 'third', 'world', 'countries', 'stifling', 'economic', 'growth', 'efforts', 'development', 'causing', 'political', 'instability', 'link', 'economic', 'development', 'environment', 'recently', 'recognized', 'encouraging', 'note', 'high', 'profile', 'given', 'environmental', 'issues', 'paris', 'summit', 'meeting', 'group', 'seven', 'july', 'year', 'regard', 'particular', 'interest', 'increasing', 'awareness', 'acceptance', 'fact', 'certain', 'technologies', 'deleterious', 'effect', 'environment', 'question', 'technologies', 'replaced', 'global', 'programme', 'co-operation', 'single', 'fact', 'single', 'object', 'defines', 'moment', 'civilization', 'existence', 'large', 'nuclear', 'arsenals', 'horrible', 'capacity', 'destroy', 'planet', 'several', 'times', 'either', 'accident', 'design', 'nuclear', 'weapons', 'instil', 'fear', 'beget', 'mistrust', 'insecurity', 'remarkable', 'tendency', 'set', 'hostile', 'relations', 'concrete', 'aggravate', 'security', 'dilemma', 'states', 'perpetuate', 'confliction', 'mode', 'behaviour', 'therefore', 'fuels', 'arms', 'race', 'defence', 'budgets', 'soar', 'expenditures', 'benevolent', 'tend', 'plummet', 'conference', 'relationship', 'disarmament', 'development', 'served', 'timely', 'reminder', 'opportunity', 'costs', 'armaments', 'nuclear', 'conventional', 'however', 'opportunity', 'cost', 'nuclear', 'weaponry', 'development', 'international', 'political', 'climate', 'security', 'perceptions', 'states', 'well', 'environment', 'actual', 'potential', 'sacrifices', 'nuclear', 'weapons', 'furthermore', 'potential', 'horizontal', 'proliferation', 'nuclear', 'weapons', 'issues', 'stark', 'grim', 'warning', 'regional', 'rivalries', 'would', 'ever', 'shorter', 'fuse', 'cataclysm', 'would', 'much', 'closer', 'view', 'strong', 'objections', 'nuclear', 'weapons', 'proliferation', 'deployment', 'delegation', 'consistently', 'strongly', 'supported', 'united', 'nations', 'calls', 'disarmament', 'confidence', 'derived', 'genuine', 'arms', 'reduction', 'pervasive', 'effect', 'security', 'environment', 'transition', 'many', 'world', 'conflict', 'making', 'towards', 'negotiations', 'understanding', 'owes', 'great', 'deal', 'improved', 'relations', 'super-powers', 'part', 'inspired', 'historic', 'arms', 'reduction', 'agreement', 'december', 'reason', '-at', 'maldives', 'always', 'supported', 'efforts', 'view', 'general', 'complete', 'disarmament', 'including', 'total', 'elimination', 'chemical', 'bacteriological', 'weapons', 'reduction', 'conventional', 'armaments', 'also', 'believe', 'nuclear-weapon-free', 'zones', 'zones', 'peace', 'could', 'inspire', 'trust', 'good', 'operation', 'among', 'states', 'transforming', 'secure', 'communities', 'contributing', 'global', 'peace', 'security', 'therefore', 'support', 'calls', 'establishment', 'nuclear-weapon-free', 'zones', 'zones', 'peace', 'express', 'delegation', 'fullest', 'support', 'people', 'namibia', 'namibia', 'achieved', 'independence', 'apartheid', 'affront', 'mankind', 'crime', 'humanity', 'amount', 'tinkering', 'placate', 'sense', 'outrage', 'indignation', 'felt', 'world', 'community', 'immoral', 'practice', 'amount', 'cosmetic', 'change', 'restore', 'justice', 'dignity', 'oppressed', 'majority', 'south', 'africa', 'maldives', 'express', 'solidarity', 'oppressed', 'majority', 'south', 'africa', 'struggle', 'apartheid', 'condemn', 'unequivocally', 'system', 'apartheid', 'condemn', 'pretoria', 'regime', 'continued', 'defiance', 'resolutions', 'far', 'greatest', 'conflict', 'time', 'continues', 'conflict', 'middle', 'east', 'heart', 'conflict', 'question', 'palestine', 'however', 'recent', 'years', 'palestinian', 'issue', 'evoked', 'even', 'reasoned', 'amount', 'concern', 'key', 'states', 'search', 'peace', 'continues', 'frustrated', 'hard-line', 'obstinate', 'policies', 'israel', 'meanwhile', 'situation', 'occupied', 'territories', 'continues', 'deteriorate', 'month', 'long', 'intifadah', 'emphasizes', 'intensity', 'situation', 'posed', 'zionist', 'occupation', 'palestine', 'arab', 'territories', 'including', 'jerusalem', 'government', 'maldives', 'strongly', 'condemns', 'use', 'brutal', 'force', 'blatant', 'abuse', 'human', 'rights', 'israel', 'palestinian', 'people', 'occupied', 'territories', 'also', 'deplore', 'continued', 'defiance', 'israel', 'united', 'nations', 'resolutions', 'violation', 'international', 'law', 'norms', 'civilized', 'behaviour', 'reiterate', 'full', 'support', 'solidarity', 'people', 'palestine', 'struggle', 'self-determination', 'independence', 'therefore', 'welcome', 'overwhelming', 'international', 'support', 'uprising', 'viewed', 'valiant', 'struggle', 'palestinian', 'people', 'restoration', 'inalienable', 'rights', 'extend', 'whole-hearted', 'support', 'proposal', 'early', 'convening', 'international', 'conference', 'middle', 'east', 'full', 'independent', 'participation', 'palestine', 'situation', 'lebanon', 'remains', 'volatile', 'civil', 'war', 'fifteenth', 'year', 'continues', 'take', 'increasing', 'toll', 'human', 'life', 'fervently', 'hope', 'developments', 'taking', 'place', 'region', 'elsewhere', 'question', 'lebanon', 'solved', 'manner', 'restore', 'independence', 'national', 'integrity', 'alleviate', 'sufferings', 'people', 'welcome', 'efforts', 'undertaken', 'members', 'arab', 'league', 'past', 'present', 'resolve', 'situation', 'lebanon', 'request', 'international', 'community', 'give', 'support', 'people', 'lebanon', 'efforts', 'solve', 'problems', 'hopeful', 'note', 'pleased', 'contrary', 'early', 'pessimistic', 'assessments', 'cease-fire', 'agreed', 'iran', 'iraq', 'gulf', 'held', 'firm', 'indicating', 'sincerity', 'parties', 'conflict', 'welcome', 'commitments', 'undertaken', 'resolve', 'conflict', 'peaceful', 'means', 'particular', 'applaud', 'efforts', 'united', 'nations', 'secretary-general', 'resolution', 'conflict', 'urge', 'parties', 'maintain', 'momentum', 'peace', 'created', 'envisaged', 'cease-fire', 'welcome', 'positive', 'developments', 'afghanistan', 'refer', 'withdraw', 'foreign', 'troops', 'regret', 'situation', 'completely', 'settled', 'reiterate', 'call', 'upon', 'parties', 'concerned', 'adhere', 'provisions', 'geneva', 'agreements', 'order', 'frustrate', 'prevailing', 'opportunities', 'lasting', 'solution', 'problem', 'urge', 'international', 'community', 'provide', 'humanitarian', 'economic', 'assistance', 'relief', 'rehabilitation', 'refugees', 'well', 'long-term', 'reconstruction', 'ravaged', 'country', 'positive', 'strides', 'taken', 'towards', 'solution', 'kampuchean', 'problem', 'welcome', 'withdraw', 'vietnamese', 'troops', 'appreciate', 'diplomatic', 'efforts', 'obtain', 'comprehensive', 'lasting', 'solution', 'dispute', 'including', 'jakarta', 'informal', 'meeting', 'well', 'international', 'conference', 'paris', 'however', 'realizing', 'delicacy', 'current', 'situation', 'call', 'upon', 'parties', 'concerned', 'exercise', 'restraint', 'process', 'reunification', 'peoples', 'peaceful', 'means', 'creation', 'conditions', 'conducive', 'reconciliation', 'peace', 'stability', 'among', 'sharing', 'aspirations', 'remain', 'optimistic', 'prospects', 'peaceful', 'national', 'reconciliation', 'korean', 'peninsula', 'good', 'office', 'could', 'utilized', 'peace', 'negotiations', 'another', 'issue', 'needs', 'attention', 'situation', 'cyprus', 'prolonged', 'inter-communal', 'dispute', 'solved', 'urgently', 'due', 'regard', 'national', 'integrity', 'nation', 'aspirations', 'peoples', 'welcome', 'recent', 'high-level', 'contacts', 'two', 'communities', 'hope', 'revived', 'inter-communal', 'dialogue', 'lead', 'inter-communal', 'reconciliation', 'basis', 'equality', 'integrity', 'communities', 'commend', 'tireless', 'sincere', 'efforts', 'secretary-general', 'searching', 'settlement', 'conflict', 'already', 'noted', 'world', 'economic', 'situation', 'continues', 'bleak', 'developing', 'countries', 'situation', 'worsened', 'limited', 'aid', 'since', 'early', 'rampant', 'domestic', 'inflation', 'crippling', 'debts', 'exorbitant', 'burden', 'debt-servicing', 'situation', 'aggravated', 'falling', 'share', 'international', 'trade', 'persistent', 'negative', 'trends', 'terms', 'trade', 'owing', 'protectionism', 'upsurge', 'unilateralism', 'practices', 'jeopardize', 'multilateral', 'nature', 'trade', 'regrettable', 'whole', 'despite', 'recent', 'measures', 'whereby', 'resources', 'international', 'finance', 'institutions', 'increased', 'plans', 'developed', 'countries', 'recycle', 'part', 'surplus', 'developing', 'countries', 'internationally', 'agreed', 'target', 'per', 'cent', 'gross', 'national', 'product', 'gnp', 'official', 'development', 'assistance', 'met', 'moreover', 'regards', 'least', 'developed', 'countries', 'continue', 'register', 'negative', 'growth', 'rates', 'official', 'development', 'assistance', 'target', 'per', 'cent', 'gnp', 'met', 'either', 'economic', 'insecurity', 'visible', 'threat', 'facing', 'many', 'world', 'today', 'indeed', 'consider', 'environment', 'one', 'important', 'aspects', 'quality', 'life', 'address', 'quest', 'economic', 'industrial', 'development', 'welcome', 'proposed', 'united', 'nations', 'conference', 'environment', 'development', 'regard', 'event', 'valuable', 'opportunity', 'fully', 'utilized', 'promote', 'comprehensive', 'approach', 'environmental', 'problems', 'related', 'development', 'activities', 'mankind', 'serious', 'efforts', 'made', 'global', 'regional', 'national', 'levels', 'protect', 'environment', 'delegation', 'particularly', 'concerned', 'effects', 'degradation', 'environment', 'especially', 'depletion', 'ozone', 'layer', 'consequent', 'global', 'warming', 'rise', 'sea', 'level', 'maldives', 'low-lying', 'archipelagic', 'state', 'entirely', 'dependent', 'upon', 'surrounding', 'seas', 'degradation', 'marine', 'ecosystem', 'rise', 'mean', 'sea', 'level', 'matter', 'grave', 'concern', 'maldives', 'recalled', 'two', 'years', 'ago', 'witnessed', 'fury', 'tidal', 'eruptions', 'caused', 'extensive', 'damage', 'assistance', 'friendly', 'countries', 'embarked', 'upon', 'programme', 'protecting', 'populated', 'islands', 'possible', 'natural', 'calamities', 'tidal', 'waves', 'hurricanes', 'typhoons', 'increasingly', 'frequent', 'phenomena', 'today', 'greater', 'awareness', 'man', 'tampering', 'environment', 'certain', 'technologies', 'inimical', 'environment', 'direct', 'bearing', 'behaviour', 'global', 'weather', 'system', 'maldives', 'therefore', 'strongly', 'supports', 'call', 'environmental', 'preservation', 'already', 'party', 'vienna', 'convention', 'protection', 'ozone', 'layer', 'montreal', 'protocol', 'substances', 'deplete', 'ozone', 'layer', 'interest', 'issue', 'continues', 'undiminished', 'welcome', 'universal', 'interest', 'expressed', 'preservation', 'environment', 'like', 'also', 'mention', 'november', 'year', 'maldives', 'host', 'conference', 'small', 'states', 'sea-level', 'rise', 'confident', 'conference', 'contribute', 'global', 'efforts', 'addressing', 'important', 'issue', 'old', 'true', 'maxim', 'best', 'indicator', 'strength', 'stability', 'international', 'security', 'system', 'political', 'order', 'survival', 'weakest', 'members', 'case', 'view', 'implications', 'ever-increasing', 'dangers', 'terrorism', 'mercenarism', 'sovereignty', 'small', 'weak', 'states', 'appalling', 'terrorism', 'simply', 'minor', 'irritant', 'anybody', 'least', 'small', 'nations', 'whose', 'sovereignty', 'held', 'hostage', 'easily', 'usurped', 'existence', 'possibility', 'first', 'place', 'augur', 'well', 'security', 'international', 'community', 'cherished', 'principles', 'long', 'contributed', 'survival', 'present', 'state', 'system', 'indispensable', 'values', 'global', 'civilization', 'stake', 'today', 'may', 'small', 'states', 'whose', 'sovereignty', 'robbed', 'handful', 'mercenaries', 'gang', 'bounty', 'hunters', 'tomorrow', 'could', 'larger', 'countries', 'even', 'present', 'face', 'erosion', 'sovereignty', 'security', 'similar', 'acts', 'difference', 'small', 'state', 'subjected', 'terrorist', 'onslaught', 'invasion', 'mercenaries', 'consequences', 'irreversible', 'political', 'economic', 'terms', 'maldives', 'close', 'becoming', 'victim', 'dastardly', 'attempt', 'last', 'november', 'evident', 'peoples', 'engaging', 'acts', 'terrorism', 'mercenarism', 'endanger', 'sovereignty', 'territorial', 'integrity', 'states', 'need', 'deterred', 'security', 'small', 'states', 'weak', 'taken', 'care', 'mere', 'self-help', 'implications', 'efforts', 'strengthen', 'security', 'prospects', 'economic', 'development', 'severe', 'affordable', 'opportunity', 'costs', 'impact', 'social', 'political', 'values', 'well', 'long-term', 'implications', 'sustenance', 'democracy', 'militarised', 'society', 'negative', 'requesting', 'inclusion', 'agenda', 'assembly', 'item', 'related', 'protection', 'security', 'small', 'states', 'sought', 'highlight', 'issue', 'mentioned', 'brought', 'issue', 'forum', 'unwilling', 'defend', 'values', 'taken', 'peoples', 'lack', 'valour', 'small', 'states', 'friends', 'states', 'assist', 'assisted', 'strengthening', 'security', 'grateful', 'sense', 'duty', 'friends', 'shown', 'regret', 'note', 'bilateral', 'security', 'arrangements', 'international', 'system', 'yet', 'evolved', 'level', 'maturity', 'whereby', 'interests', 'weaker', 'partner', 'safeguarded', 'socio-political', 'identity', 'weaker', 'state', 'principle', 'sovereign', 'equality', 'strong', 'enough', 'impervious', 'possible', 'vicissitudes', 'unequal', 'relationships', 'moreover', 'political', 'systems', 'continue', 'afflicted', 'misconceptions', 'distort', 'actions', 'taken', 'best', 'intentions', 'consequently', 'greater', 'power', 'differential', 'greater', 'propensity', 'misconceptions', 'hapless', 'predicament', 'weaker', 'parties', 'reason', 'believe', 'multilateral', 'frameworks', 'feasible', 'nodes', 'sound', 'security', 'mechanism', 'weakest', 'members', 'organization', 'even', 'actual', 'support', 'assistance', 'given', 'situation', 'rendered', 'regional', 'bilateral', 'level', 'noted', 'earlier', 'humble', 'opinion', 'pivotal', 'point', 'important', 'crossroads', 'global', 'political', 'development', 'belief', 'particularly', 'auspicious', 'moment', 'history', 'forge', 'ahead', 'strengthening', 'norms', 'global', 'political', 'security', 'systems', 'thus', 'sincere', 'hope', 'organization', 'take', 'similar', 'momentous', 'step', 'leap', 'forward', 'ushering', 'new', 'era', 'security', 'small', 'states', 'trust', 'critical', 'step', 'taken', 'safeguard', 'principles', 'espoused', 'organization', 'survival', 'large', 'number', 'community', 'depends']\n"
     ]
    }
   ],
   "source": [
    "transcripts = clean_debates(debates)\n",
    "print(transcripts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73057\n"
     ]
    }
   ],
   "source": [
    "# dictionary contains unique words and frequency\n",
    "dictionary = corpora.Dictionary(transcripts)\n",
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert document into the bag-of-words (BoW) format = list of (token_id, token_count) tuples.\n",
    "corpus = [dictionary.doc2bow(transcript) for transcript in transcripts]\n",
    "\n",
    "count_vect = CountVectorizer(max_df=.90, min_df=2, max_features=1000)\n",
    "tfidf_vect = TfidfVectorizer(max_df=.90, min_df=2, max_features=1000)\n",
    "\n",
    "counts = count_vect.fit_transform(debates[\"text\"][:100])\n",
    "count_total = np.array(counts.sum(axis=0))[0]\n",
    "count_vocab = count_vect.vocabulary_\n",
    "count_feats = np.array(count_vect.get_feature_names())\n",
    "\n",
    "tfidfs = tfidf_vect.fit_transform(debates[\"text\"][:100])\n",
    "tfidf_vocab = tfidf_vect.vocabulary_\n",
    "tfidf_feats = np.array(count_vect.get_feature_names())\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of debates: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging Debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = [nltk.pos_tag(transcript) for transcript in transcripts[:1]]\n",
    "# print(pos[0][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a7c8fbd0fb9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscripts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    338\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[1;32m    339\u001b[0m                                                 max_length=self.max_length))\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got list)"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(transcripts)\n",
    "print(len(doc.ents))\n",
    "\n",
    "print([(X.text, X.label_) for X in doc.ents[:20]])\n",
    "\n",
    "labels = [x.label_ for x in doc.ents]\n",
    "Counter(labels)\n",
    "\n",
    "items= [x.text for x in doc.ents]\n",
    "Counter(items).most_common(3)\n",
    "\n",
    "sentences = [x for x in doc.sents]\n",
    "print(sentences[21])\n",
    "\n",
    "displacy.render(nlp(str(sentences[21])), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 2\n",
    "\n",
    "#suggestion from https://www.kaggle.com/ykhorramz/lda-and-t-sne-interactive-visualization\n",
    "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "lda_model = models.LdaModel(corpus=gensim_corpus, num_topics=num_topics, id2word=dictionary, eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"LDA Model:\")\n",
    " \n",
    "# for idx in range(num_topic):\n",
    "#     # Print the first 10 most representative topics\n",
    "#     print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 10))\n",
    " \n",
    "# print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(x, Z, top_n=5):\n",
    "    dists = euclidean_distances(x.reshape(1, -1), Z)\n",
    "    pairs = enumerate(dists[0])\n",
    "    most_similar = sorted(pairs, key=lambda item: item[1], sort=False)[:top_n]\n",
    "    return most_similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.gensim.prepare(lda_model, gensim_corpus, gensim_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left panel, labeld Intertopic Distance Map, circles represent different topics and the distance between them. Similar topics appear closer and the dissimilar topics farther. The relative size of a topic's circle in the plot corresponds to the relative frequency of the topic in the corpus. An individual topic may be selected for closer scrutiny by clicking on its circle, or entering its number in the \"selected topic\" box in the upper-left.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The right panel, include the bar chart of the top 30 terms. When no topic is selected in the plot on the left, the bar chart shows the top-30 most \"salient\" terms in the corpus. A term's saliency is a measure of both how frequent the term is in the corpus and how \"distinctive\" it is in distinguishing between different topics. Selecting each topic on the right, modifies the bar chart to show the \"relevant\" terms for the selected topic. Relevence is defined as in footer 2 and can be tuned by parameter  λ\n",
    " , smaller  λ\n",
    "  gives higher weight to the term's distinctiveness while larger  λ\n",
    " s corresponds to probablity of the term occurance per topics.\n",
    "\n",
    "Therefore, to get a better sense of terms per topic we'll use  λ\n",
    " =0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_corpus = lda_model[gensim_corpus] \n",
    "\n",
    "def explore_topic(lda_model, topic_number, topn, output=True):\n",
    "    \"\"\"\n",
    "    accept a ldamodel, a topic number and top n vocabs of interest\n",
    "    prints a formatted list of the top n terms\n",
    "    \"\"\"\n",
    "    terms = []\n",
    "    for term, frequency in lda_model.show_topic(topic_number, topn=topn):\n",
    "        terms += [term]\n",
    "        if output:\n",
    "            print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))\n",
    "    \n",
    "    return terms\n",
    "\n",
    "topic_summaries = []\n",
    "print(u'{:20} {}'.format(u'term', u'frequency') + u'\\n')\n",
    "for i in range(num_topics):\n",
    "    print('Topic '+str(i)+' |---------------------\\n')\n",
    "    tmp = explore_topic(lda_model,topic_number=i, topn=10, output=True )\n",
    "#     print tmp[:5]\n",
    "    topic_summaries += [tmp[:5]]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_labels = {'Disarment???'}\n",
    "print(len(debates['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tvectorizer = TfidfVectorizer(input='content', analyzer = 'word', lowercase=True, stop_words='english',\\\n",
    "                                  tokenizer=tokens, ngram_range=(1, 3), min_df=40, max_df=0.20,\\\n",
    "                                  norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs\n",
    "docs1 = debates['text'].apply(lambda l: l[:int(len(l)/2)])\n",
    "docs2 = debates['text'].apply(lambda l: l[int(len(l)/2):])\n",
    "\n",
    "corpus1 = [gensim_dictionary.doc2bow(doc) for doc in docs1]\n",
    "corpus2 = [gensim_dictionary.doc2bow(doc) for doc in docs2]\n",
    "\n",
    "# Using the corpus LDA model tranformation\n",
    "lda_corpus1 = model[corpus1]\n",
    "lda_corpus2 = model[corpus2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_topic_dist(model, corpus, kwords=False):\n",
    "    top_dist =[]\n",
    "    keys = []\n",
    "    for d in gensim_corpus:\n",
    "        tmp = {i:0 for i in range(num_topics)}\n",
    "        tmp.update(dict(lda_model[d]))\n",
    "        vals = list(OrderedDict(tmp).values())\n",
    "        top_dist += [(vals)] #removed array\n",
    "        if kwords:\n",
    "                keys += [(vals).argmax()]\n",
    "        return [(top_dist)], keys\n",
    "    \n",
    "top_dist1, _ = get_doc_topic_dist(lda_model, lda_corpus1)\n",
    "top_dist2, _ = get_doc_topic_dist(lda_model, lda_corpus2)\n",
    "\n",
    "\n",
    "print(\"Intra similarity: cosine similarity for corresponding parts of a doc(higher is better):\")\n",
    "print(np.mean([cosine_similarity(c1.reshape(1, -1), c2.reshape(1, -1))[0][0] for c1,c2 in zip(top_dist1, top_dist2)]))\n",
    "\n",
    "random_pairs = np.random.randint(0, len(databases['text']), size=(400, 2))\n",
    "\n",
    "print(\"Inter similarity: cosine similarity between random parts (lower is better):\")\n",
    "print(np.mean([cosine_similarity(top_dist1[i[0]].reshape(1, -1), top_dist2[i[1]].reshape(1, -1)) for i in random_pairs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis & ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and Further Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data:**  \n",
    "After loading our data, we realized there some issues as we were cleaning our data.\n",
    "- Countries have not stayed consistent in history.\n",
    "    - They have broken apart, merged, and etc.\n",
    "- UN representative also changes overtime \n",
    "    - Rhetoric of the transcript for each country will not be consistent\n",
    "- The formal language at the UN constraints much of the variation that occurs in regular colloquium\n",
    "- These transcriptions are translated\n",
    "    -  There is evidence that meaning can be lost through language translation\n",
    "    \n",
    "From this, we concluded that it was not clear that the transcripts could provide insight on the country that was speaking. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
